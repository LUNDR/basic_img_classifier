{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading https://files.pythonhosted.org/packages/9c/88/06cdc6239013e13aec97f474638fc4e7c00e5b7fb954a1d0ec2a5fc8db7a/opencv_python-4.1.1.26-cp36-cp36m-win_amd64.whl (39.0MB)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\lundr\\appdata\\local\\continuum\\anaconda3\\envs\\dogscats\\lib\\site-packages (from opencv-python) (1.17.3)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.1.1.26\n"
     ]
    }
   ],
   "source": [
    "#! pip install tensorflow\n",
    "#! pip install tflearn\n",
    "#! pip install tqdm\n",
    "#! pip install opencv-python\n",
    "#! pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Activation, Dropout, Flatten\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "# data downloaded from kaggle, saved locally\n",
    "TRAIN_DIR='C:/Users/lundr/dogscats/train'\n",
    "TEST_DIR='C:/Users/lundr/dogscats/test'\n",
    "#we're going to resize images so they are all 50 x 50 pixels\n",
    "IMG_SIZE=50\n",
    "LR=1e-3\n",
    "\n",
    "MODEL_NAME= 'dogsvcats -{}-{}.model'.format(LR, '2conv-basic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the images then allocate each image a vector, \n",
    "def label_img(img):\n",
    "    #files are named cat1.img etc, so we first get rid of the \n",
    "    word_label = img.split('.')[0][:3]\n",
    "    if word_label =='cat': return [1,0]\n",
    "    elif word_label =='dog': return [1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    X_train = []\n",
    "    Y_train=[]\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(TRAIN_DIR,img)\n",
    "        img = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE),(IMG_SIZE, IMG_SIZE))\n",
    "        X_train.append([np.array(img)])\n",
    "        Y_train.append([np.array(label)])\n",
    "    #shuffle(training_data)\n",
    "    np.save('Y_train.npy', Y_train)\n",
    "    np.save('X_train.npy', X_train)\n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data():\n",
    "    X_test = []\n",
    "    Y_test=[]\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        label = label_img(img\n",
    "        path = os.path.join(TEST_DIR,img)\n",
    "        img = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE),(IMG_SIZE, IMG_SIZE))\n",
    "        X_test.append([np.array(img)])\n",
    "        Y_test.append([np.array(label)])\n",
    "    #shuffle(testing_data)\n",
    "    np.save('Y_test.npy', Y_train)\n",
    "    np.save('X_test.npy', X_train)\n",
    "    return X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 25000/25000 [00:39<00:00, 627.64it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 12500/12500 [00:21<00:00, 588.64it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = create_train_data()\n",
    "X_test, Y_test = process_test_data()\n",
    "# If you have already created the dataset:\n",
    "#train_data = np.load('train_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make x and y into tensors\n",
    "#Y_train = K.constant(Y_train)\n",
    "#X_train = K.constant(X_train)\n",
    "\n",
    "Y_train=np.array(Y_train)\n",
    "X_train=np.array(X_train)\n",
    "#Y_test=np.array(Y_test)\n",
    "#X_test=np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500, 1)\n",
      "(12500, 1, 50, 50)\n"
     ]
    }
   ],
   "source": [
    "#print(Y_test.shape)\n",
    "#print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array(None, dtype=object)], dtype=object)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=keras.layers.Flatten(data_format=None)(X_train)\n",
    "Y_train=keras.layers.Flatten(data_format=None)(Y_train)\n",
    "#X_test=keras.layers.Flatten(data_format=None)(X_test)\n",
    "#Y_test=keras.layers.Flatten(data_format=None)(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([25000, 2500])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequential  multi-layer perceptron\n",
    "model = Sequential()\n",
    "\n",
    "# The model expects rows of data with 2 variables input dimensions.\n",
    "model.add(Dense(32, input_dim=2500, activation='relu'))\n",
    "\n",
    "# The output layer has one node and uses the sigmoid activation function.\n",
    "model.add(Dense(2, activation='sigmoid')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adadelta(),\n",
    "              loss=keras.losses.binary_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 32)                80032     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 80,098\n",
      "Trainable params: 80,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "30/30 [==============================] - ETA: 7s - loss: 4.5850 - accuracy: 0.99 - ETA: 6s - loss: 4.5379 - accuracy: 0.99 - ETA: 5s - loss: 4.4913 - accuracy: 0.99 - ETA: 5s - loss: 4.4454 - accuracy: 0.99 - ETA: 4s - loss: 4.4002 - accuracy: 0.99 - ETA: 4s - loss: 4.3558 - accuracy: 0.99 - ETA: 4s - loss: 4.3121 - accuracy: 0.99 - ETA: 4s - loss: 4.2693 - accuracy: 0.99 - ETA: 3s - loss: 4.2273 - accuracy: 0.99 - ETA: 3s - loss: 4.1860 - accuracy: 0.99 - ETA: 3s - loss: 4.1456 - accuracy: 0.99 - ETA: 3s - loss: 4.1059 - accuracy: 0.99 - ETA: 3s - loss: 4.0670 - accuracy: 0.99 - ETA: 2s - loss: 4.0288 - accuracy: 0.99 - ETA: 2s - loss: 3.9914 - accuracy: 0.99 - ETA: 2s - loss: 3.9546 - accuracy: 0.99 - ETA: 2s - loss: 3.9186 - accuracy: 0.99 - ETA: 2s - loss: 3.8832 - accuracy: 0.99 - ETA: 1s - loss: 3.8485 - accuracy: 0.99 - ETA: 1s - loss: 3.8144 - accuracy: 0.99 - ETA: 1s - loss: 3.7809 - accuracy: 0.99 - ETA: 1s - loss: 3.7480 - accuracy: 0.99 - ETA: 1s - loss: 3.7157 - accuracy: 0.99 - ETA: 1s - loss: 3.6839 - accuracy: 0.99 - ETA: 0s - loss: 3.6527 - accuracy: 0.99 - ETA: 0s - loss: 3.6221 - accuracy: 0.99 - ETA: 0s - loss: 3.5919 - accuracy: 0.99 - ETA: 0s - loss: 3.5623 - accuracy: 0.99 - ETA: 0s - loss: 3.5332 - accuracy: 0.99 - 5s 175ms/step - loss: 3.5046 - accuracy: 0.9997\n",
      "Epoch 2/6\n",
      "30/30 [==============================] - ETA: 4s - loss: 2.6323 - accuracy: 0.99 - ETA: 4s - loss: 2.6117 - accuracy: 0.99 - ETA: 4s - loss: 2.5914 - accuracy: 0.99 - ETA: 4s - loss: 2.5715 - accuracy: 0.99 - ETA: 4s - loss: 2.5520 - accuracy: 0.99 - ETA: 4s - loss: 2.5328 - accuracy: 0.99 - ETA: 3s - loss: 2.5140 - accuracy: 0.99 - ETA: 3s - loss: 2.4955 - accuracy: 0.99 - ETA: 3s - loss: 2.4773 - accuracy: 0.99 - ETA: 3s - loss: 2.4594 - accuracy: 0.99 - ETA: 3s - loss: 2.4418 - accuracy: 0.99 - ETA: 3s - loss: 2.4245 - accuracy: 0.99 - ETA: 2s - loss: 2.4074 - accuracy: 0.99 - ETA: 2s - loss: 2.3906 - accuracy: 0.99 - ETA: 2s - loss: 2.3741 - accuracy: 0.99 - ETA: 2s - loss: 2.3578 - accuracy: 0.99 - ETA: 2s - loss: 2.3418 - accuracy: 0.99 - ETA: 2s - loss: 2.3260 - accuracy: 0.99 - ETA: 1s - loss: 2.3104 - accuracy: 0.99 - ETA: 1s - loss: 2.2950 - accuracy: 0.99 - ETA: 1s - loss: 2.2799 - accuracy: 0.99 - ETA: 1s - loss: 2.2649 - accuracy: 0.99 - ETA: 1s - loss: 2.2502 - accuracy: 0.99 - ETA: 1s - loss: 2.2357 - accuracy: 0.99 - ETA: 0s - loss: 2.2213 - accuracy: 0.99 - ETA: 0s - loss: 2.2072 - accuracy: 0.99 - ETA: 0s - loss: 2.1932 - accuracy: 0.99 - ETA: 0s - loss: 2.1794 - accuracy: 0.99 - ETA: 0s - loss: 2.1657 - accuracy: 0.99 - 5s 169ms/step - loss: 2.1522 - accuracy: 0.9999\n",
      "Epoch 3/6\n",
      "30/30 [==============================] - ETA: 5s - loss: 1.7390 - accuracy: 0.99 - ETA: 4s - loss: 1.7282 - accuracy: 0.99 - ETA: 4s - loss: 1.7175 - accuracy: 0.99 - ETA: 4s - loss: 1.7068 - accuracy: 0.99 - ETA: 4s - loss: 1.6963 - accuracy: 0.99 - ETA: 4s - loss: 1.6859 - accuracy: 0.99 - ETA: 4s - loss: 1.6756 - accuracy: 0.99 - ETA: 3s - loss: 1.6653 - accuracy: 0.99 - ETA: 3s - loss: 1.6552 - accuracy: 0.99 - ETA: 3s - loss: 1.6451 - accuracy: 0.99 - ETA: 3s - loss: 1.6352 - accuracy: 0.99 - ETA: 3s - loss: 1.6253 - accuracy: 0.99 - ETA: 2s - loss: 1.6156 - accuracy: 0.99 - ETA: 2s - loss: 1.6059 - accuracy: 0.99 - ETA: 2s - loss: 1.5963 - accuracy: 0.99 - ETA: 2s - loss: 1.5869 - accuracy: 0.99 - ETA: 2s - loss: 1.5775 - accuracy: 0.99 - ETA: 2s - loss: 1.5682 - accuracy: 0.99 - ETA: 1s - loss: 1.5590 - accuracy: 0.99 - ETA: 1s - loss: 1.5499 - accuracy: 0.99 - ETA: 1s - loss: 1.5408 - accuracy: 0.99 - ETA: 1s - loss: 1.5319 - accuracy: 0.99 - ETA: 1s - loss: 1.5231 - accuracy: 0.99 - ETA: 1s - loss: 1.5144 - accuracy: 0.99 - ETA: 0s - loss: 1.5057 - accuracy: 0.99 - ETA: 0s - loss: 1.4972 - accuracy: 0.99 - ETA: 0s - loss: 1.4887 - accuracy: 0.99 - ETA: 0s - loss: 1.4804 - accuracy: 0.99 - ETA: 0s - loss: 1.4721 - accuracy: 0.99 - 5s 177ms/step - loss: 1.4640 - accuracy: 0.9999\n",
      "Epoch 4/6\n",
      "30/30 [==============================] - ETA: 5s - loss: 1.2135 - accuracy: 0.99 - ETA: 4s - loss: 1.2068 - accuracy: 0.99 - ETA: 4s - loss: 1.2002 - accuracy: 0.99 - ETA: 4s - loss: 1.1936 - accuracy: 0.99 - ETA: 4s - loss: 1.1871 - accuracy: 0.99 - ETA: 4s - loss: 1.1806 - accuracy: 0.99 - ETA: 4s - loss: 1.1742 - accuracy: 0.99 - ETA: 3s - loss: 1.1678 - accuracy: 0.99 - ETA: 3s - loss: 1.1615 - accuracy: 1.00 - ETA: 3s - loss: 1.1552 - accuracy: 1.00 - ETA: 3s - loss: 1.1489 - accuracy: 1.00 - ETA: 3s - loss: 1.1427 - accuracy: 1.00 - ETA: 3s - loss: 1.1366 - accuracy: 1.00 - ETA: 2s - loss: 1.1305 - accuracy: 1.00 - ETA: 2s - loss: 1.1244 - accuracy: 1.00 - ETA: 2s - loss: 1.1184 - accuracy: 1.00 - ETA: 2s - loss: 1.1124 - accuracy: 1.00 - ETA: 2s - loss: 1.1065 - accuracy: 1.00 - ETA: 1s - loss: 1.1006 - accuracy: 1.00 - ETA: 1s - loss: 1.0948 - accuracy: 1.00 - ETA: 1s - loss: 1.0890 - accuracy: 1.00 - ETA: 1s - loss: 1.0832 - accuracy: 1.00 - ETA: 1s - loss: 1.0775 - accuracy: 1.00 - ETA: 1s - loss: 1.0718 - accuracy: 1.00 - ETA: 0s - loss: 1.0662 - accuracy: 1.00 - ETA: 0s - loss: 1.0606 - accuracy: 1.00 - ETA: 0s - loss: 1.0551 - accuracy: 1.00 - ETA: 0s - loss: 1.0496 - accuracy: 1.00 - ETA: 0s - loss: 1.0441 - accuracy: 1.00 - 5s 180ms/step - loss: 1.0387 - accuracy: 1.0000\n",
      "Epoch 5/6\n",
      "30/30 [==============================] - ETA: 5s - loss: 0.8723 - accuracy: 1.00 - ETA: 5s - loss: 0.8677 - accuracy: 1.00 - ETA: 5s - loss: 0.8630 - accuracy: 1.00 - ETA: 4s - loss: 0.8584 - accuracy: 1.00 - ETA: 4s - loss: 0.8538 - accuracy: 1.00 - ETA: 4s - loss: 0.8493 - accuracy: 1.00 - ETA: 4s - loss: 0.8448 - accuracy: 1.00 - ETA: 4s - loss: 0.8404 - accuracy: 1.00 - ETA: 3s - loss: 0.8360 - accuracy: 1.00 - ETA: 3s - loss: 0.8316 - accuracy: 1.00 - ETA: 3s - loss: 0.8272 - accuracy: 1.00 - ETA: 3s - loss: 0.8229 - accuracy: 1.00 - ETA: 3s - loss: 0.8187 - accuracy: 1.00 - ETA: 2s - loss: 0.8144 - accuracy: 1.00 - ETA: 2s - loss: 0.8102 - accuracy: 1.00 - ETA: 2s - loss: 0.8061 - accuracy: 1.00 - ETA: 2s - loss: 0.8020 - accuracy: 1.00 - ETA: 2s - loss: 0.7979 - accuracy: 1.00 - ETA: 2s - loss: 0.7938 - accuracy: 1.00 - ETA: 1s - loss: 0.7898 - accuracy: 1.00 - ETA: 1s - loss: 0.7858 - accuracy: 1.00 - ETA: 1s - loss: 0.7818 - accuracy: 1.00 - ETA: 1s - loss: 0.7779 - accuracy: 1.00 - ETA: 1s - loss: 0.7740 - accuracy: 1.00 - ETA: 0s - loss: 0.7701 - accuracy: 1.00 - ETA: 0s - loss: 0.7662 - accuracy: 1.00 - ETA: 0s - loss: 0.7624 - accuracy: 1.00 - ETA: 0s - loss: 0.7586 - accuracy: 1.00 - ETA: 0s - loss: 0.7548 - accuracy: 1.00 - 5s 181ms/step - loss: 0.7511 - accuracy: 1.0000\n",
      "Epoch 6/6\n",
      "30/30 [==============================] - ETA: 4s - loss: 0.6358 - accuracy: 1.00 - ETA: 4s - loss: 0.6325 - accuracy: 1.00 - ETA: 4s - loss: 0.6292 - accuracy: 1.00 - ETA: 4s - loss: 0.6259 - accuracy: 1.00 - ETA: 4s - loss: 0.6227 - accuracy: 1.00 - ETA: 4s - loss: 0.6195 - accuracy: 1.00 - ETA: 3s - loss: 0.6163 - accuracy: 1.00 - ETA: 3s - loss: 0.6131 - accuracy: 1.00 - ETA: 3s - loss: 0.6100 - accuracy: 1.00 - ETA: 3s - loss: 0.6069 - accuracy: 1.00 - ETA: 3s - loss: 0.6037 - accuracy: 1.00 - ETA: 3s - loss: 0.6007 - accuracy: 1.00 - ETA: 2s - loss: 0.5976 - accuracy: 1.00 - ETA: 2s - loss: 0.5946 - accuracy: 1.00 - ETA: 2s - loss: 0.5915 - accuracy: 1.00 - ETA: 2s - loss: 0.5885 - accuracy: 1.00 - ETA: 2s - loss: 0.5856 - accuracy: 1.00 - ETA: 2s - loss: 0.5826 - accuracy: 1.00 - ETA: 1s - loss: 0.5797 - accuracy: 1.00 - ETA: 1s - loss: 0.5768 - accuracy: 1.00 - ETA: 1s - loss: 0.5739 - accuracy: 1.00 - ETA: 1s - loss: 0.5710 - accuracy: 1.00 - ETA: 1s - loss: 0.5682 - accuracy: 1.00 - ETA: 1s - loss: 0.5653 - accuracy: 1.00 - ETA: 0s - loss: 0.5625 - accuracy: 1.00 - ETA: 0s - loss: 0.5597 - accuracy: 1.00 - ETA: 0s - loss: 0.5570 - accuracy: 1.00 - ETA: 0s - loss: 0.5542 - accuracy: 1.00 - ETA: 0s - loss: 0.5515 - accuracy: 1.00 - 5s 174ms/step - loss: 0.5488 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1c62311ff60>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 6\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=6, verbose=1,steps_per_epoch=30)\n",
    "\n",
    "#model.fit({'input': X_train}, {'targets': Y_train}, n_epoch=3, validation_set=({'input': X_train}, {'targets': Y_train}), \n",
    " #   snapshot_step=500, show_metric=True, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.015504556894302367\n",
      "Test accuracy: 29.99880015850067\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, Y_train, verbose=0, steps=30)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Required argument 'shape' (pos 1) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-d18d581e1fd9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: Required argument 'shape' (pos 1) not found"
     ]
    }
   ],
   "source": [
    "turn list of num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
